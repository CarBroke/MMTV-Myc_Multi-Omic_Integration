{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "314149ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Full Python Script\n",
    "# Python 3.8.8\n",
    "# Pandas 1.2.4\n",
    "# Numpy 1.20.1\n",
    "# Carson Broeker, 10/19/2021\n",
    "#Test script for converting Delly and Lumpy BND vcf data to a list of genes\n",
    "# First, import necessary modules\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "# Make it so really large files don't cause the system to error out\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "# Next, read in all of the VCF files from Delly and Lumpy using a for loop\n",
    "# This step also gets rid of superfluous columns for downstream analyses\n",
    "# Modify the List elements to suit your project needs\n",
    "# Make sure all of your vcf files are in the same directory/location as this python script\n",
    "#dfFVBL = pd.read_csv(\"FVB_NJLumpy.vcf\", sep='\\t', skiprows=32, usecols=[0,1,4,7], engine = 'c', dtype=object)\n",
    "#dfFVBL = dfFVBL[(dfFVBL['ALT'] == '<DUP>') | (dfFVBL['ALT'] == '<DEL>')]\n",
    "#dfFVBL['END'] = dfFVBL['INFO'].str.extract(';END=(\\d+)')\n",
    "#dfFVBL['POS'] = dfFVBL['POS'].astype(int)\n",
    "#dfFVBL['END'] = dfFVBL['END'].astype(int)\n",
    "#dfFVBL['LENGTH'] = dfFVBL['END'] - dfFVBL['POS']\n",
    "#dfFVBL = dfFVBL.sort_values(by=['POS'])\n",
    "#dfFVBL = dfFVBL[dfFVBL['LENGTH'] > 10000]\n",
    "#dfFVBL = dfFVBL[dfFVBL['LENGTH'] < 100000000]\n",
    "#dfFVBL['SU'] = dfFVBL['INFO'].str.extract(';SU=(\\d+)')\n",
    "#dfFVBL['SU'] = dfFVBL['SU'].astype(int)\n",
    "#dfFVBL = dfFVBL[dfFVBL['SU'] > 4]\n",
    "#dfFVBL['CIPOS'] = dfFVBL['INFO'].str.extract(';CIPOS=-(\\d+,\\d+)')\n",
    "#dfFVBL['CIEND'] = dfFVBL['INFO'].str.extract(';CIEND=-(\\d+,\\d+)')\n",
    "\n",
    "#dfWTFVB = pd.read_csv(\"WTFVBLumpy.vcf\", sep='\\t', skiprows=32, usecols=[0,1,4,7], engine = 'c', dtype=object)\n",
    "#dfWTFVB = dfWTFVB[(dfWTFVB['ALT'] == '<DUP>') | (dfWTFVB['ALT'] == '<DEL>')]\n",
    "#dfWTFVB['END'] = dfWTFVB['INFO'].str.extract(';END=(\\d+)')\n",
    "#dfWTFVB['POS'] = dfWTFVB['POS'].astype(int)\n",
    "#dfWTFVB['END'] = dfWTFVB['END'].astype(int)\n",
    "#dfWTFVB['LENGTH'] = dfWTFVB['END'] - dfWTFVB['POS']\n",
    "#dfWTFVB = dfWTFVB.sort_values(by=['POS'])\n",
    "#dfWTFVB = dfWTFVB[dfWTFVB['LENGTH'] > 10000]\n",
    "\n",
    "#dfFVBD = pd.read_csv(\"FVB_NJDelly.vcf\", sep='\\t', skiprows=107, usecols=[0,1,4,6,7], engine = 'c', dtype=object)\n",
    "#dfFVBD = dfFVBD[(dfFVBD['ALT'] == '<DUP>') | (dfFVBD['ALT'] == '<DEL>')]\n",
    "#dfFVBD = dfFVBD[dfFVBD['FILTER'] == 'PASS']\n",
    "#dfFVBD['END'] = dfFVBD['INFO'].str.extract(';END=(\\d+)')\n",
    "#dfFVBD['POS'] = dfFVBD['POS'].astype(int)\n",
    "#dfFVBD['END'] = dfFVBD['END'].astype(int)\n",
    "#dfFVBD['LENGTH'] = dfFVBD['END'] - dfFVBD['POS']\n",
    "#dfFVBD = dfFVBD.sort_values(by=['POS'])\n",
    "#dfFVBD = dfFVBD[dfFVBD['LENGTH'] > 10000]\n",
    "#dfFVBD = dfFVBD[dfFVBD['LENGTH'] < 100000000]\n",
    "#dfFVBD['PE'] = dfFVBD['INFO'].str.extract(';PE=(\\d+);')\n",
    "#dfFVBD['SR'] = dfFVBD['INFO'].str.extract(';SR=(\\d+);')\n",
    "#dfFVBD['PE'] = dfFVBD['PE'].astype(int)\n",
    "#dfFVBD['SR'] = dfFVBD['SR'].fillna(0)\n",
    "#dfFVBD['SR'] = dfFVBD['SR'].astype(int)\n",
    "#dfFVBD['SU'] = dfFVBD['PE'] + dfFVBD['SR']\n",
    "#dfFVBD['SU'] = dfFVBD['SU'].astype(int)\n",
    "#dfFVBD = dfFVBD[dfFVBD['SU'] > 4]\n",
    "#dfFVBD['CIPOS'] = dfFVBD['INFO'].str.extract(';CIPOS=-(\\d+,\\d+)')\n",
    "#dfFVBD['CIEND'] = dfFVBD['INFO'].str.extract(';CIEND=-(\\d+,\\d+)')\n",
    "\n",
    "Myc_List = ['TA39_927','TA41_1938','WT13_842','WT13_864','WT13_1356','WT13_1445','WT13_1576','WT21_222','WT21_1066']\n",
    "#Myc_List = ['3790']\n",
    "for base in Myc_List:\n",
    "    Lumpy_base = pd.read_csv(base+\"LumpyAnnotated.vcf\", sep='\\t', skiprows=37, usecols=[0,1,4,7,9,10], \\\n",
    "                             engine = 'c', dtype=object)\n",
    "# Must be loaded as engine='c' as the 'python' engine isn't natively equipped with the necessary modules\n",
    "# Next, make each dataframe something easier to read and obvious\n",
    "# If unsure how to modify data, look at the python pandas documentation\n",
    "    df1 = Lumpy_base\n",
    "# Use masking to include only columns that have deletions or duplications, no inversions or translocations\n",
    "    df1 = df1[df1['INFO'].str.contains('BND', na=False)]\n",
    "# We want predicted highly impactful BNDs, so only keep those that are predicted to be have a HIGH impact\n",
    "    df1 = df1[df1['INFO'].str.contains('HIGH')]\n",
    "# Extract the BND end position using regular expressions\n",
    "# Check python regular expression documentation for more info\n",
    "    df1['DONOR_CHROM'] = df1['ALT'].str.extract('([a-zA-Z0-9]+):')\n",
    "    df1['DONOR_POS'] = df1['ALT'].str.extract(':([a-zA-Z0-9]+)')\n",
    "    df1['RECEIVER_CHROM'] = df1['#CHROM']\n",
    "    df1['RECEIVER_POS'] = df1['POS']\n",
    "    df1['RECEIVER_POS'] = df1['RECEIVER_POS'].astype(int)\n",
    "    df1['DONOR_POS'] = df1['DONOR_POS'].astype(int)\n",
    "    #df1 = df1[df1['LENGTH'] > 10000]\n",
    "    #df1['SU'] = df1['INFO'].str.extract(';SU=(\\d+)')\n",
    "    #df1['SU'] = df1['SU'].astype(int)\n",
    "    #df1 = df1[df1['SU'] > 4]\n",
    "    #df1['CIPOS'] = df1['INFO'].str.extract(';CIPOS=-(\\d+,\\d+)')\n",
    "    #df1['CIEND'] = df1['INFO'].str.extract(';CIEND=-(\\d+,\\d+)')\n",
    "    df1['GENE'] = df1['INFO'].str.extract('\\|HIGH\\|(.*?)\\|')\n",
    "    df1['TYPE'] = df1['INFO'].str.extract('\\|(.*?)\\|HIGH\\|')\n",
    "    df1[base+'_EVIDENCE'] = df1[base+'AlignedAddedreadgroupSorted'].str.extract('./.:(\\d+):')\n",
    "    df1[base+'_EVIDENCE'] = df1[base+'_EVIDENCE'].astype(int)\n",
    "    df1['FVB_NJ_EVIDENCE'] = df1['FVB_NJ'].str.extract('./.:(\\d+):')\n",
    "    df1['FVB_NJ_EVIDENCE'] = df1['FVB_NJ_EVIDENCE'].astype(int)\n",
    "    df1 = df1[df1['FVB_NJ_EVIDENCE'] <= 0]\n",
    "    df1['TUMOR_MINUS_BACKGROUND_EVIDENCE'] = df1[base+'_EVIDENCE'] - df1['FVB_NJ_EVIDENCE']\n",
    "    df1['TUMOR_MINUS_BACKGROUND_EVIDENCE'] = df1['TUMOR_MINUS_BACKGROUND_EVIDENCE'].astype(int)\n",
    "    df1 = df1.sort_values(by=['RECEIVER_POS'])\n",
    "    #dfFVBL = dfFVBL.sort_values(by=['DONOR_POS'])\n",
    "    \n",
    "    #df1WTFVB = pd.merge_asof(df1, dfWTFVB, on=['POS'], by=[\"#CHROM\"], direction=\"nearest\")\n",
    "    #df1WTFVB[\"NEW_LENGTH\"] = df1WTFVB['LENGTH_x'] - df1WTFVB['LENGTH_y']\n",
    "    #df1WTFVB['NEW_LENGTH'] = df1WTFVB['NEW_LENGTH'].abs()\n",
    "    #df1WTFVB = df1WTFVB[df1WTFVB['NEW_LENGTH'] < 100]\n",
    "    #df1newnew = pd.concat([df1, df1WTFVB]).drop_duplicates(subset=['#CHROM','POS'], keep=False)\n",
    "    #df1newnew.replace('', np.nan, inplace=True)\n",
    "    #df1newnew.dropna(axis='columns', inplace=True)\n",
    "    \n",
    "    #df1FVBL = pd.merge_asof(df1, dfFVBL, on=['POS'], by=[\"#CHROM\"], direction=\"nearest\")\n",
    "    #df1FVBL[\"NEW_LENGTH\"] = df1FVBL['LENGTH_x'] - df1FVBL['LENGTH_y']\n",
    "    #df1FVBL['NEW_LENGTH'] = df1FVBL['NEW_LENGTH'].abs()\n",
    "    #df1FVBL = df1FVBL[df1FVBL['NEW_LENGTH'] < 100]\n",
    "    #df1new = df1new.reset_index()\n",
    "    #df1FVBL = df1FVBL.reset_index()\n",
    "    #df1new = pd.concat([df1, df1FVBL]).drop_duplicates(subset=['#CHROM','POS'], keep=False)\n",
    "    #df1new.replace('', np.nan, inplace=True)\n",
    "    #df1new.dropna(axis='columns', inplace=True)\n",
    "    \n",
    "    \n",
    "# Read in Delly VCF files\n",
    "    Delly_base = pd.read_csv(base+\"DellyAnnotated.vcf\", sep='\\t', skiprows=112, usecols=[0,1,4,6,7], \\\n",
    "                             engine = 'c', dtype=object)\n",
    "    df2 = Delly_base\n",
    "    df2 = df2[df2['INFO'].str.contains('BND', na=False)]\n",
    "# Filter out low quality calls\n",
    "    df2 = df2[df2['FILTER'] == 'PASS']\n",
    "    df2 = df2[df2['INFO'].str.contains('HIGH|MODERATE')]\n",
    "    df2['MAPQ'] = df2['INFO'].str.extract(';MAPQ=(\\d+);').astype(int)\n",
    "    df2['DONOR_CHROM'] = df2['ALT'].str.extract('([a-zA-Z0-9]+):')\n",
    "    df2['DONOR_POS'] = df2['ALT'].str.extract(':([a-zA-Z0-9]+)')\n",
    "    df2['RECEIVER_CHROM'] = df2['#CHROM']\n",
    "    df2['RECEIVER_POS'] = df2['POS']\n",
    "    df2['RECEIVER_POS'] = df2['RECEIVER_POS'].astype(int)\n",
    "    df2['DONOR_POS'] = df2['DONOR_POS'].astype(int)\n",
    "    #df2 = df2[df2['LENGTH'] < 100000000]\n",
    "    df2['GENE'] = df2['INFO'].str.extract('\\|HIGH\\|(.*?)\\|')\n",
    "    df2['TYPE'] = df2['INFO'].str.extract('\\|(.*?)\\|HIGH\\|')\n",
    "    #df2['CIPOS'] = df2['INFO'].str.extract(';CIPOS=-(\\d+,\\d+)')\n",
    "    #df2['CIEND'] = df2['INFO'].str.extract(';CIEND=-(\\d+,\\d+)')\n",
    "    df2 = df2.sort_values(by=['RECEIVER_POS'])\n",
    "    \n",
    "    #df2FVBD = pd.merge_asof(df2, dfFVBD, on=['POS'], by=[\"#CHROM\"], direction=\"nearest\")\n",
    "    #df2FVBD[\"NEW_LENGTH\"] = df2FVBD['LENGTH_x'] - df2FVBD['LENGTH_y']\n",
    "    #df2FVBD['NEW_LENGTH'] = df2FVBD['NEW_LENGTH'].abs()\n",
    "    #df2FVBD = df2FVBD[df2FVBD['NEW_LENGTH'] < 100]\n",
    "    #df2new = pd.concat([df2, df2FVBD]).drop_duplicates(subset=['#CHROM','POS'], keep=False)\n",
    "# Merge Delly and Lumpy dataframes based on Columns of interest\n",
    "# The chromosomes, position on the chromosome, and type of BND should all match\n",
    "# There may be slight deviations on start and end position\n",
    "# You can try to build in a base pair buffer if you want, but I don't know how\n",
    "    \n",
    "    df = pd.merge_asof(df2, df1, on=['RECEIVER_POS'], by=[\"DONOR_CHROM\",\"RECEIVER_CHROM\"], direction=\"nearest\")\n",
    "    df['POS_DIFF'] = df['DONOR_POS_x'] - df['DONOR_POS_y']\n",
    "    df['POS_DIFF'] = df['POS_DIFF'].abs()\n",
    "    df = df[df['POS_DIFF'] < 1000]\n",
    "    df = df[df['MAPQ'] >= 50]\n",
    "    df['FINAL_DONOR_POS'] = df[['DONOR_POS_x', 'DONOR_POS_y']].mean(axis=1).round().astype(int)\n",
    "    df['MM_DONOR_CHROM'] = 'mm' + df['DONOR_CHROM'].astype(str)\n",
    "    df['MM_RECEIVER_CHROM'] = 'mm' + df['RECEIVER_CHROM'].astype(str)\n",
    "    df['CIRCOS_COLOR'] = 'color=color'+df['MM_DONOR_CHROM']\n",
    "    #df['SU_AVERAGE'] = df[['SU_x', 'SU_y']].mean(axis=1).round().astype(int)\n",
    "    #df = df.sort_values(by=['SU_AVERAGE'], ascending=False)\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.dropna(axis='columns', inplace=True)\n",
    "    \n",
    "    df = df.sort_values(by=['TUMOR_MINUS_BACKGROUND_EVIDENCE'], ascending=False)\n",
    "    with pd.ExcelWriter('Myc_'+base+'_BND.xlsx') as writer:\n",
    "        df.to_excel(writer, sheet_name='Total_BND_Info')\n",
    "        df.to_excel(writer, sheet_name='Circos', columns=['MM_DONOR_CHROM','FINAL_DONOR_POS','FINAL_DONOR_POS'\\\n",
    "                                                          ,'MM_RECEIVER_CHROM','RECEIVER_POS','RECEIVER_POS','CIRCOS_COLOR'])\n",
    "    df['Chromosome 1'] = df['DONOR_CHROM']\n",
    "    df['Position 1'] = df['FINAL_DONOR_POS']\n",
    "    df['Chromosome 2'] = df['RECEIVER_CHROM']\n",
    "    df['Position 2'] = df['RECEIVER_POS']\n",
    "    df['Gene(s)'] = df['GENE_x']\n",
    "    df['Effect'] = df['TYPE_x']\n",
    "    with pd.ExcelWriter('Myc_'+base+'_BNDs_Pub.xlsx') as writer:\n",
    "        df.to_excel(writer, sheet_name='Total Info', columns=['Chromosome 1','Position 1','Chromosome 2','Position 2','Gene(s)','Effect'])\n",
    "# Create an empty list\n",
    "    BND_baseList1 = pd.DataFrame()\n",
    "# Extract gene names to list and remove duplicates\n",
    "# Delly and Lumpy often call the same BND twice or more, so remove all extra instances of a gene\n",
    "# This will be important for later when you want to count instances of a gene across multiple tumors\n",
    "    BND_baseList1 = df['GENE_x'].str.split(',')\n",
    "    BND_baseList1 = BND_baseList1.explode().reset_index(drop=True)\n",
    "    BND_baseList1.drop_duplicates(keep='first', inplace=True)\n",
    "    BND_baseList1.to_csv('Myc_'+base+'_BND_Gene_List.csv', sep='\\t')\n",
    "# Import Counter for counting instances of each gene to gain a consensus\n",
    "from collections import Counter\n",
    "total_gene_list = []\n",
    "total_gene_list.clear()\n",
    "Myc_List = ['TA39_927','TA41_1938','WT13_842','WT13_864','WT13_1356','WT13_1445','WT13_1576','WT21_222','WT21_1066']\n",
    "#Myc_List = ['3790']\n",
    "for base in Myc_List:\n",
    "# Read in csv files to a dataframe\n",
    "    dfbase = pd.read_csv('Myc_'+base+'_BND_Gene_List.csv', sep='\\t', usecols=[1])\n",
    "    dfbase.dropna(axis='rows', inplace=True)\n",
    "# Convert dataframe to a list\n",
    "# This gets rid of a problem where I had numbers always sticking to the front of my genes\n",
    "    base_gene_list = dfbase.values.tolist()\n",
    "# Append each gene list read in through the for loop to the total gene list\n",
    "# There may be many duplicates of genes in this list, so we're going to count them\n",
    "    total_gene_list.append(base_gene_list)\n",
    "# The total gene list right now is a list of lists of lists\n",
    "# The Counter function doesn't work on lists, as lists themselves are not hashable\n",
    "# For two separate times, convert shrink down this list of lists of lists to only a list\n",
    "    flat_total_gene_list = [item for sublist in total_gene_list for item in sublist]\n",
    "    final_flat_total_gene_list = [item for sublist in flat_total_gene_list for item in sublist]\n",
    "# Call your counter of the final flat total gene list to something smaller for simplicity\n",
    "albert = Counter(final_flat_total_gene_list)\n",
    "# The counter function gives you a dictionary in python terms\n",
    "# Each gene count is assigned to each gene name\n",
    "# We want to write this to a csv file and must do so using a method specifically for dictionaries\n",
    "with open('Myc_BND_Total_Gene_Count.csv','w') as csvfile:\n",
    "    fieldnames=['Gene', 'Count']\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(fieldnames)\n",
    "    for key, value in albert.items():\n",
    "        writer.writerow((key, value))\n",
    "# After being returned as a csvfile, there may be a couple rows with values like '0' or 'nan' which you can remove manually\n",
    "# Congrats, you now have your BND gene names and how many tumors they were present in\n",
    "# Modify this code to your heart's content\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b641659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Combine Delly, Lumpy, and CNVkit calls for BNDs\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "Myc_List = ['TA39_927','TA41_1938','WT13_842','WT13_864','WT13_1356','WT13_1445','WT13_1576','WT21_222','WT21_1066']\n",
    "#Myc_List = ['TA39_927']\n",
    "for base in Myc_List:\n",
    "    BND_base = pd.read_excel(\"Myc_\"+base+\"_BND.xlsx\")\n",
    "    BND_base[\"Gene\"] = BND_base[\"GENE_x\"].str.split('&')\n",
    "    BND_base = BND_base.explode(\"Gene\")\n",
    "    BND_base = BND_base.drop_duplicates(subset=[\"Gene\"])\n",
    "    Gene_breaks_base = pd.read_csv(base+\"_gene_breaks.txt\", delimiter=\"\\t\", \n",
    "                                   names=[\"Gene\",\"Chromosome\",\"Position\",\"Change_Log2\",\"Probes_Left\",\"Probes_Right\"]\n",
    "                                  )#.explode(Gene_breaks_base.assign(Gene=Gene_breaks_base.Gene.str.split(',')), 'Gene')\n",
    "    Gene_breaks_base[\"Gene\"] = Gene_breaks_base[\"Gene\"].str.split(',')\n",
    "    Gene_breaks_base = Gene_breaks_base.explode(\"Gene\")\n",
    "    Gene_breaks_base = Gene_breaks_base.drop_duplicates(subset=[\"Gene\"])\n",
    "    df_base = BND_base.merge(Gene_breaks_base, how='inner', on=[\"Gene\"])\n",
    "    \n",
    "    with pd.ExcelWriter('Myc_'+base+'_Final_Translocations.xlsx') as writer:\n",
    "        df_base.to_excel(writer, sheet_name='Total_BND_Info')\n",
    "        df_base.to_excel(writer, sheet_name='Circos', columns=['MM_DONOR_CHROM','FINAL_DONOR_POS','FINAL_DONOR_POS'\\\n",
    "                                                          ,'MM_RECEIVER_CHROM','RECEIVER_POS','RECEIVER_POS','CIRCOS_COLOR'])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd948236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
